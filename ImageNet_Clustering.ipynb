{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageNet Siamese.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpLtlFJfiXhNDk7t7A1EMT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkwave/COVID-19/blob/master/ImageNet_Clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3dpRbltJgtl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "9e8bcc79-4bdf-4004-e2b4-d6262a32a24a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cm70i6H-Lkav",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1041ff17-fa87-4b6c-c7ab-2b0ab096a437"
      },
      "source": [
        "from utils import get_dataset, PairGenerator, test_embedding, visualize_deformation, plot_losses\n",
        "from networks import pairwise_embedding_encoder, get_embedding_model, pairwise_embedding_network, get_encoding_model\n",
        "from losses import contrastive_loss, reconstruction_loss\n",
        "from training import train_network\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHdd7AMuLkfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY3Qe9u-LklQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dBUPktiLksg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu4fqT9hNJ3U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8ijl-a1NJ5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## define training params. \n",
        "margin = 1\n",
        "p_norm = 2 \n",
        "batch_size = 32\n",
        "\n",
        "## specify model parameters and losses. \n",
        "model_type = 'embenc'\n",
        "optimizer = Adam(learning_rate=0.01)\n",
        "activation = 'sigmoid'\n",
        "num_neurons = 300\n",
        "output_dim = 2\n",
        "input_dim = (1, trainX.shape[-1])\n",
        "loss1 = lambda y_true, y_pred: contrastive_loss(y_true, y_pred, margin=margin, norm=p_norm)\n",
        "loss2 = lambda y_true, y_pred: reconstruction_loss(y_true, y_pred)\n",
        "losses = {'reconstruction': loss2,\n",
        "          'embedding': loss1}\n",
        "epochs = 5\n",
        "max_iters = 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg1e6an3NJ7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## create generator\n",
        "tripgen = PairGenerator(trainX, trainY)\n",
        "\n",
        "## create the model. \n",
        "if model_type == 'embenc':\n",
        "    model = pairwise_embedding_encoder(input_dim, output_dim, num_neurons=num_neurons,\n",
        "                                       losses=losses, optimizer=optimizer, f=activation,\n",
        "                                       mu=0.75, autoencoding_layers=[100])\n",
        "elif model_type == 'siamese':\n",
        "    model = pairwise_embedding_network(input_dim, output_dim, num_neurons, loss1, optimizer, f=activation)\n",
        "\n",
        "## visualize model topology. \n",
        "plot_model(model, 'full_model.png', expand_nested=True, show_shapes=True)\n",
        "plot_model(model.get_layer('encodingnet'), 'encodingnet.png', expand_nested=True, show_shapes=True)\n",
        "plot_model(model.get_layer('embeddingnet'), 'embeddingnet.png', expand_nested=True, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rlmIBhCNJ-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## train network \n",
        "model, losses = train_network(model, tripgen, batch_size, max_iters, type_=model_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_1wYQrwNKAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ## visualize the embeddings. \n",
        "embedding_model = get_embedding_model(model, input_dim=input_dim)\n",
        "embedding = embedding_model.predict(trainX.reshape(-1, 1, input_dim[-1]))\n",
        "embedding = embedding.reshape(embedding.shape[0], embedding.shape[2])\n",
        "embedding_fig = test_embedding(trainX, trainY, embedding)\n",
        "# # original_fig, embedded_fig_no_noise, embedding_fig_noise, vector_field = visualize_deformation(embedding_model, input_dim)    \n",
        "# encoding_model = get_encoding_model(model, input_dim=input_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WIbEo9cNKCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
        "import pandas as pd \n",
        "img_w, img_h = 28,28\n",
        "zoom = 0.5\n",
        "\n",
        "# subsample a section of both dataframes in a stratified fashion. \n",
        "inds = [] \n",
        "for cl in set(trainY):\n",
        "    cl_inds = np.random.choice(np.where(trainY == cl)[0],\n",
        "                               500,\n",
        "                               replace=False)\n",
        "    inds.extend(cl_inds)\n",
        "\n",
        "plt_trainX = pd.DataFrame(trainX[inds, :]).reset_index(drop=True)\n",
        "plt_embedding = embedding[inds, :]\n",
        "print(plt_embedding.shape)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(24,16))\n",
        "\n",
        "for i, row in plt_trainX.iterrows():\n",
        "    image = row.values.reshape((img_w, img_h))\n",
        "    im = OffsetImage(image, zoom=0.3)\n",
        "    ab = AnnotationBbox(im, (plt_embedding[i, 0], plt_embedding[i, 1]), xycoords='data', frameon=False)\n",
        "    ax.add_artist(ab)\n",
        "    ax.update_datalim([(embedding[i, 0], embedding[i, 1])])\n",
        "    ax.autoscale()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNIW5qjvNKEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}